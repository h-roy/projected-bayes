{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from jax import random\n",
    "import json\n",
    "import datetime\n",
    "from src.losses import sse_loss\n",
    "from src.helper import calculate_exact_ggn, tree_random_normal_like\n",
    "from src.sampling.predictive_samplers import sample_predictive, sample_hessian_predictive\n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "from jax import flatten_util\n",
    "import matplotlib.pyplot as plt\n",
    "import tree_math as tm\n",
    "from src.laplace.diagonal import hutchinson_diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return jnp.sin(5 * x + 1) #+ jnp.cos(25 * x + 1) + jnp.exp(0.1 * x) + 5\n",
    "param_dict = pickle.load(open(\"../checkpoints/syntetic_regression.pickle\", \"rb\"))\n",
    "params = param_dict['params']\n",
    "alpha = param_dict['alpha']\n",
    "rho = param_dict['rho']\n",
    "x_train, y_train, x_val, y_val, model, D = param_dict[\"train_stats\"]['x_train'],param_dict[\"train_stats\"]['y_train'],param_dict[\"train_stats\"]['x_val'],param_dict[\"train_stats\"]['y_val'],param_dict[\"train_stats\"]['model'], param_dict[\"train_stats\"]['n_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = jax.random.PRNGKey(100)\n",
    "model_fn = lambda params, x: model.apply(params, x[None, ...])[0]\n",
    "n_params = D \n",
    "def sse_loss(preds, y):\n",
    "    residual = preds - y\n",
    "    return 0.5 * jnp.sum(residual**2)\n",
    "\n",
    "ggn = calculate_exact_ggn(sse_loss, model_fn, params, x_train, y_train, n_params)\n",
    "true_diag = jnp.diag(ggn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013861573\n"
     ]
    }
   ],
   "source": [
    "model_fn = model.apply\n",
    "gvp_batch_size = 25\n",
    "N = x_train.shape[0]//gvp_batch_size\n",
    "data_array = x_train[: N * gvp_batch_size].reshape((N, gvp_batch_size)+ x_train.shape[1:])\n",
    "n_samples = 10000\n",
    "diag_hutch = hutchinson_diagonal(model_fn, params, gvp_batch_size, n_samples, sample_key, data_array, \"regression\", num_levels=5, computation_type=\"serial\")\n",
    "diag_hutch, _ = jax.flatten_util.ravel_pytree(diag_hutch)\n",
    "print(jnp.linalg.norm(diag_hutch - true_diag) / jnp.linalg.norm(true_diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.laplace.diagonal import exact_diagonal\n",
    "output_dim = 1\n",
    "exact_diag = exact_diagonal(model.apply, params, output_dim, x_train, x_train.shape[0], \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.138341e-08\n"
     ]
    }
   ],
   "source": [
    "exact_diag, _ = jax.flatten_util.ravel_pytree(exact_diag)\n",
    "print(jnp.linalg.norm(exact_diag - true_diag) / jnp.linalg.norm(true_diag))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
